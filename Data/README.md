# Web Scraping
1> We started with a site https://www.totaltraininfo.com/ and extracted links of sites of different types of trains.
<img width="1440" alt="Screenshot 2023-10-02 at 2 13 57 AM" src="https://github.com/dootika/class-project-data_manics/assets/124786081/13017492-1a80-4a6b-8d39-1b2c3ffd0219">
<br>
<br>
<br>
2> Then we extracted the different type of train names from the links which will be used further.
<br>
<br>
<br>
3> After that we moved to webpage of each train and extracted data_table of each type of train and stored it in a list.  

  
<img width="1440" alt="Screenshot 2023-10-02 at 2 25 31 AM" src="https://github.com/dootika/class-project-data_manics/assets/124786081/f29a4b5d-71fb-4f09-a967-71dcf099a3bf">
<br>
<br>
<br>
4>We cleaned the data and added a column of train_type and merged all the tables of list in a single table.<br>
<br>
<br>  
5>Now we wanted to scrape average delays of train in past one year forw which we used this site https://runningstatus.in/history/. 
<br>
<br>
<br>
<img width="1440" alt="Screenshot 2023-10-02 at 2 32 03 AM" src="https://github.com/dootika/class-project-data_manics/assets/124786081/532234a5-54f7-44e7-b51a-e269d8bbca41">
<br>
<br>
<br>
6> Then we created links of each train and went to that page and then scraped the average delays of the trains.<br>
<br>
<br>
<img width="1440" alt="Screenshot 2023-10-02 at 2 31 45 AM" src="https://github.com/dootika/class-project-data_manics/assets/124786081/f362ce30-9bd2-4474-9237-44bd6086606a">
<br>
<br>
<br>
7> Finally we cleaned all the data and created our final data_set.


